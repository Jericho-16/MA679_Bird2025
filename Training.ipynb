{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b1d041c",
   "metadata": {},
   "source": [
    "Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a19814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm #import timm\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import lr_scheduler  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e63de45",
   "metadata": {},
   "source": [
    "Testing trunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edf1777",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    taxonomy_csv = \"taxonomy.csv\"         # species ID to label mapping\n",
    "    train_datadir = \"Denoise1\"            # root of PNG folder\n",
    "    TARGET_SHAPE = (256, 256)             # shape of spectrogram image\n",
    "    aug_prob = 0.5                        # augmentation probability\n",
    "    seed = 42\n",
    "    debug = False                         # limit to 1000 samples if True\n",
    "    LOAD_DATA = False                     # set to False to use spectrograms dict\n",
    "\n",
    "\n",
    "# === Paths ===\n",
    "train_csv = \"train.csv\"               # ← your BirdCLEF official file\n",
    "spectrogram_root = Path(\"Denoise1\")   # ← where your spectrogram PNGs are\n",
    "\n",
    "# === Load train.csv and extract ogg stem names\n",
    "df_train = pd.read_csv(train_csv)\n",
    "df_train['ogg_stem'] = df_train['filename'].apply(lambda x: Path(x).stem)\n",
    "\n",
    "# === Scan spectrograms and match with train.csv\n",
    "records = []\n",
    "\n",
    "# for folder in spectrogram_root.glob(\"*\"):\n",
    "#     if folder.is_dir():\n",
    "#         for f in folder.glob(\"*.png\"):\n",
    "#             folder_id = folder.name\n",
    "#             png_name = f.name\n",
    "#             png_stem = f.stem.split(\"_seg\")[0]  # e.g., iNat65519\n",
    "\n",
    "#             match = df_train[df_train['ogg_stem'] == png_stem]\n",
    "#             if not match.empty:\n",
    "#                 row = match.iloc[0]\n",
    "#                 records.append({\n",
    "#                     \"filename\": f\"{folder_id}/{png_name}\",\n",
    "#                     \"primary_label\": row[\"primary_label\"],\n",
    "#                     \"secondary_labels\": row.get(\"secondary_labels\", \"[]\")\n",
    "#                 })\n",
    "#             else:\n",
    "#                 print(f\" No match found for {png_stem}\")\n",
    "\n",
    "# # === Save metadata.csv\n",
    "# df_meta = pd.DataFrame(records)\n",
    "# df_meta.to_csv(\"metadata_5s_denoise.csv\", index=False)\n",
    "# print(f\" metadata_5s_denoise.csv saved with {len(df_meta)} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1779f5",
   "metadata": {},
   "source": [
    "Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ab0e55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # === General Settings ===\n",
    "    seed = 42\n",
    "    debug = False                   # If True, limits dataset to 1000 samples\n",
    "    apex = False\n",
    "    print_freq = 100\n",
    "    num_workers = 0\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    # === Paths ===\n",
    "    taxonomy_csv = \"taxonomy.csv\"         # species ID to label mapping\n",
    "    train_csv = \"metadata_5s_denoise.csv\"            # metadata linking PNG to label\n",
    "    train_datadir = \"Denoise1\"            # directory containing PNG spectrograms\n",
    "\n",
    "    # === Spectrogram Settings ===\n",
    "    LOAD_DATA = False                     # False to load directly from PNG\n",
    "    in_channels = 3                       # RGB PNG images\n",
    "    TARGET_SHAPE = (256, 256)\n",
    "\n",
    "    # === Audio Parameters (if needed elsewhere) ===\n",
    "    FS = 32000\n",
    "    TARGET_DURATION = 5.0\n",
    "    N_FFT = 1024\n",
    "    HOP_LENGTH = 512\n",
    "    N_MELS = 128\n",
    "    FMIN = 50\n",
    "    FMAX = 14000\n",
    "\n",
    "    # === Model and Training ===\n",
    "    model_name = 'efficientnet_b0'\n",
    "    pretrained = True\n",
    "    epochs = 5\n",
    "    batch_size = 32\n",
    "    criterion = 'BCEWithLogitsLoss'\n",
    "    optimizer = 'AdamW'\n",
    "    lr = 5e-4\n",
    "    weight_decay = 1e-5\n",
    "    scheduler = 'CosineAnnealingLR'\n",
    "    min_lr = 1e-6\n",
    "    T_max = epochs\n",
    "\n",
    "    # === Cross-Validation ===\n",
    "    n_fold = 5\n",
    "    selected_folds = [0, 1, 2, 3, 4]\n",
    "\n",
    "    # === Augmentation ===\n",
    "    aug_prob = 0.5\n",
    "    mixup_alpha = 0.5\n",
    "\n",
    "    # === Debug Shortcut ===\n",
    "    def update_debug_settings(self):\n",
    "        if self.debug:\n",
    "            self.epochs = 2\n",
    "            self.selected_folds = [0]\n",
    "\n",
    "# Create config object\n",
    "cfg = CFG()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e277bd",
   "metadata": {},
   "source": [
    "Loading specturm from png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bbb2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCLEFDatasetFromPNG(Dataset):\n",
    "    def __init__(self, df, cfg, mode=\"train\"):\n",
    "        self.df = df\n",
    "        self.cfg = cfg\n",
    "        self.mode = mode\n",
    "\n",
    "        taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
    "        self.species_ids = taxonomy_df['primary_label'].tolist()\n",
    "        self.num_classes = len(self.species_ids)\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(self.species_ids)}\n",
    "\n",
    "        # Generate sample names and filepaths\n",
    "        self.df['filepath'] = self.df['filename'].apply(lambda x: os.path.join(cfg.train_datadir, x))\n",
    "        self.df['samplename'] = self.df['filename'].apply(lambda x: f\"{x.split('/')[0]}-{Path(x).stem}\")\n",
    "\n",
    "        if cfg.debug:\n",
    "            self.df = self.df.sample(min(1000, len(self.df)), random_state=cfg.seed).reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        filepath = row['filepath']\n",
    "        samplename = row['samplename']\n",
    "        \n",
    "\n",
    "        try:\n",
    "            img = Image.open(filepath).convert(\"RGB\").resize(self.cfg.TARGET_SHAPE)\n",
    "            spec = np.array(img).astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "            spec = torch.tensor(spec).permute(2, 0, 1)  # [C, H, W]\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error loading image {filepath}: {e}\")\n",
    "            spec = torch.zeros(3, *self.cfg.TARGET_SHAPE)\n",
    "\n",
    "        if self.mode == \"train\" and random.random() < self.cfg.aug_prob:\n",
    "            spec = self.apply_spec_augmentations(spec)\n",
    "\n",
    "        target = self.encode_label(row['primary_label'])\n",
    "\n",
    "        if 'secondary_labels' in row and pd.notna(row['secondary_labels']) and row['secondary_labels'] not in [[''], None]:\n",
    "            try:\n",
    "                secondary_labels = eval(row['secondary_labels']) if isinstance(row['secondary_labels'], str) else row['secondary_labels']\n",
    "                for label in secondary_labels:\n",
    "                    if label in self.label_to_idx:\n",
    "                        target[self.label_to_idx[label]] = 1.0\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Failed to parse secondary_labels for {samplename}: {e}\")\n",
    "\n",
    "        return {\n",
    "            'melspec': spec,\n",
    "            'target': torch.tensor(target, dtype=torch.float32),\n",
    "            'filename': row['filename']\n",
    "        }\n",
    "\n",
    "    def apply_spec_augmentations(self, spec):\n",
    "        if random.random() < 0.5:\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                width = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[2] - width)\n",
    "                spec[:, :, start:start + width] = 0\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                height = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[1] - height)\n",
    "                spec[:, start:start + height, :] = 0\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            gain = random.uniform(0.8, 1.2)\n",
    "            bias = random.uniform(-0.1, 0.1)\n",
    "            spec = torch.clamp(spec * gain + bias, 0, 1)\n",
    "\n",
    "        return spec\n",
    "\n",
    "    def encode_label(self, label):\n",
    "        target = np.zeros(self.num_classes, dtype=np.float32)\n",
    "        if label in self.label_to_idx:\n",
    "            target[self.label_to_idx[label]] = 1.0\n",
    "        return target\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    if len(batch) == 0:\n",
    "        return {}\n",
    "\n",
    "    result = {key: [] for key in batch[0].keys()}\n",
    "\n",
    "    for item in batch:\n",
    "        for key, value in item.items():\n",
    "            result[key].append(value)\n",
    "\n",
    "    for key in result:\n",
    "        if key == 'target':\n",
    "            result[key] = torch.stack(result[key])\n",
    "        elif key == 'melspec':\n",
    "            shapes = [t.shape for t in result[key]]\n",
    "            if len(set(str(s) for s in shapes)) == 1:\n",
    "                result[key] = torch.stack(result[key])\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5187d7a",
   "metadata": {},
   "source": [
    "Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b500c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCLEFModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
    "        cfg.num_classes = len(taxonomy_df)\n",
    "        \n",
    "        self.backbone = timm.create_model(\n",
    "            cfg.model_name,\n",
    "            pretrained=cfg.pretrained,\n",
    "            in_chans=cfg.in_channels,\n",
    "            drop_rate=0.2,\n",
    "            drop_path_rate=0.2\n",
    "        )\n",
    "        \n",
    "        if 'efficientnet' in cfg.model_name:\n",
    "            backbone_out = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "        elif 'resnet' in cfg.model_name:\n",
    "            backbone_out = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "        else:\n",
    "            backbone_out = self.backbone.get_classifier().in_features\n",
    "            self.backbone.reset_classifier(0, '')\n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "            \n",
    "        self.feat_dim = backbone_out\n",
    "        \n",
    "        self.classifier = nn.Linear(backbone_out, cfg.num_classes)\n",
    "        \n",
    "        self.mixup_enabled = hasattr(cfg, 'mixup_alpha') and cfg.mixup_alpha > 0\n",
    "        if self.mixup_enabled:\n",
    "            self.mixup_alpha = cfg.mixup_alpha\n",
    "            \n",
    "    def forward(self, x, targets=None):\n",
    "    \n",
    "        if self.training and self.mixup_enabled and targets is not None:\n",
    "            mixed_x, targets_a, targets_b, lam = self.mixup_data(x, targets)\n",
    "            x = mixed_x\n",
    "        else:\n",
    "            targets_a, targets_b, lam = None, None, None\n",
    "        \n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        if isinstance(features, dict):\n",
    "            features = features['features']\n",
    "            \n",
    "        if len(features.shape) == 4:\n",
    "            features = self.pooling(features)\n",
    "            features = features.view(features.size(0), -1)\n",
    "        \n",
    "        logits = self.classifier(features)\n",
    "        \n",
    "        if self.training and self.mixup_enabled and targets is not None:\n",
    "            loss = self.mixup_criterion(F.binary_cross_entropy_with_logits, \n",
    "                                       logits, targets_a, targets_b, lam)\n",
    "            return logits, loss\n",
    "            \n",
    "        return logits\n",
    "    \n",
    "    def mixup_data(self, x, targets):\n",
    "        \"\"\"Applies mixup to the data batch\"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        lam = np.random.beta(self.mixup_alpha, self.mixup_alpha)\n",
    "\n",
    "        indices = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "        mixed_x = lam * x + (1 - lam) * x[indices]\n",
    "        \n",
    "        return mixed_x, targets, targets[indices], lam\n",
    "    \n",
    "    def mixup_criterion(self, criterion, pred, y_a, y_b, lam):\n",
    "        \"\"\"Applies mixup to the loss function\"\"\"\n",
    "        return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62256d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, cfg):\n",
    "    \"\"\"\n",
    "    Create an optimizer for training.\n",
    "    Chooses based on the option set in cfg.optimizer.\n",
    "    \"\"\"\n",
    "    if cfg.optimizer == 'Adam':\n",
    "        # Adam optimizer (adaptive learning rate)\n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=cfg.lr,\n",
    "            weight_decay=cfg.weight_decay\n",
    "        )\n",
    "    elif cfg.optimizer == 'AdamW':\n",
    "        # AdamW optimizer (better for weight decay regularization)\n",
    "        optimizer = optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=cfg.lr,\n",
    "            weight_decay=cfg.weight_decay\n",
    "        )\n",
    "    elif cfg.optimizer == 'SGD':\n",
    "        # Stochastic Gradient Descent with momentum\n",
    "        optimizer = optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr=cfg.lr,\n",
    "            momentum=0.9,\n",
    "            weight_decay=cfg.weight_decay\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Optimizer {cfg.optimizer} is not supported.\")\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def get_scheduler(optimizer, cfg):\n",
    "    \"\"\"\n",
    "    Set the learning rate scheduler to adjust learning rate during training.\n",
    "    Returns None if the scheduler is not needed or not implemented.\n",
    "    \"\"\"\n",
    "    if cfg.scheduler == 'CosineAnnealingLR':\n",
    "        # Slowly reduce learning rate following a cosine curve\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=cfg.T_max,\n",
    "            eta_min=cfg.min_lr\n",
    "        )\n",
    "    elif cfg.scheduler == 'ReduceLROnPlateau':\n",
    "        # Reduce learning rate when validation loss stops improving\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=2,\n",
    "            min_lr=cfg.min_lr,\n",
    "            verbose=True\n",
    "        )\n",
    "    elif cfg.scheduler == 'StepLR':\n",
    "        # Reduce learning rate by half after every few epochs\n",
    "        scheduler = lr_scheduler.StepLR(\n",
    "            optimizer,\n",
    "            step_size=cfg.epochs // 3,\n",
    "            gamma=0.5\n",
    "        )\n",
    "    elif cfg.scheduler == 'OneCycleLR':\n",
    "        # OneCycle is created in the training loop instead\n",
    "        scheduler = None\n",
    "    else:\n",
    "        # If no valid scheduler is specified\n",
    "        scheduler = None\n",
    "\n",
    "    return scheduler\n",
    "\n",
    "\n",
    "def get_criterion(cfg):\n",
    "    \"\"\"\n",
    "    Choose the loss function based on cfg.criterion.\n",
    "    \"\"\"\n",
    "    if cfg.criterion == 'BCEWithLogitsLoss':\n",
    "        # Binary Cross-Entropy with logits (used for multi-label classification)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Loss function {cfg.criterion} is not supported.\")\n",
    "\n",
    "    return criterion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5f9b10",
   "metadata": {},
   "source": [
    "Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68f11ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, device, scheduler=None):\n",
    "    \"\"\"\n",
    "    Train the model for one full pass through the training data.\n",
    "    Only uses 50% of the data in each epoch for faster training during development.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    losses = []\n",
    "    all_targets = []\n",
    "    all_outputs = []\n",
    "\n",
    "    data_iter = iter(loader)\n",
    "    total_steps = int(0.5 * len(loader))  # Use only half of the training data\n",
    "\n",
    "    pbar = tqdm(range(total_steps), total=total_steps, desc=\"Training\")\n",
    "\n",
    "    for step in pbar:\n",
    "        try:\n",
    "            batch = next(data_iter)\n",
    "        except StopIteration:\n",
    "            break  # No more data\n",
    "\n",
    "        # Handle batches where melspectrograms are in a list format\n",
    "        if isinstance(batch['melspec'], list):\n",
    "            batch_outputs = []\n",
    "            batch_losses = []\n",
    "\n",
    "            for i in range(len(batch['melspec'])):\n",
    "                inputs = batch['melspec'][i].unsqueeze(0).to(device)\n",
    "                target = batch['target'][i].unsqueeze(0).to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output = model(inputs)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "\n",
    "                batch_outputs.append(output.detach().cpu())\n",
    "                batch_losses.append(loss.item())\n",
    "\n",
    "            optimizer.step()\n",
    "            outputs = torch.cat(batch_outputs, dim=0).numpy()\n",
    "            loss = np.mean(batch_losses)\n",
    "            targets = batch['target'].numpy()\n",
    "\n",
    "        else:\n",
    "            # Standard batch format\n",
    "            inputs = batch['melspec'].to(device)\n",
    "            targets = batch['target'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Some models may return (output, loss) together\n",
    "            if isinstance(outputs, tuple):\n",
    "                outputs, loss = outputs\n",
    "            else:\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            targets = targets.detach().cpu().numpy()\n",
    "\n",
    "        # Step the learning rate scheduler if it’s being used\n",
    "        if scheduler is not None and isinstance(scheduler, lr_scheduler.OneCycleLR):\n",
    "            scheduler.step()\n",
    "\n",
    "        all_outputs.append(outputs)\n",
    "        all_targets.append(targets)\n",
    "        losses.append(loss if isinstance(loss, float) else loss.item())\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            'train_loss': np.mean(losses[-10:]) if losses else 0,\n",
    "            'lr': optimizer.param_groups[0]['lr']\n",
    "        })\n",
    "\n",
    "    # Combine all outputs and targets and calculate average loss and AUC\n",
    "    all_outputs = np.concatenate(all_outputs)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "    auc = calculate_auc(all_targets, all_outputs)\n",
    "    avg_loss = np.mean(losses)\n",
    "\n",
    "    return avg_loss, auc\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Run the model on validation data (no gradient updates).\n",
    "    Returns loss and AUC for evaluation.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    all_targets = []\n",
    "    all_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Validation\"):\n",
    "            # Handle individual spectrograms (list format)\n",
    "            if isinstance(batch['melspec'], list):\n",
    "                batch_outputs = []\n",
    "                batch_losses = []\n",
    "\n",
    "                for i in range(len(batch['melspec'])):\n",
    "                    inputs = batch['melspec'][i].unsqueeze(0).to(device)\n",
    "                    target = batch['target'][i].unsqueeze(0).to(device)\n",
    "\n",
    "                    output = model(inputs)\n",
    "                    loss = criterion(output, target)\n",
    "\n",
    "                    batch_outputs.append(output.detach().cpu())\n",
    "                    batch_losses.append(loss.item())\n",
    "\n",
    "                outputs = torch.cat(batch_outputs, dim=0).numpy()\n",
    "                loss = np.mean(batch_losses)\n",
    "                targets = batch['target'].numpy()\n",
    "\n",
    "            else:\n",
    "                inputs = batch['melspec'].to(device)\n",
    "                targets = batch['target'].to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                outputs = outputs.detach().cpu().numpy()\n",
    "                targets = targets.detach().cpu().numpy()\n",
    "\n",
    "            all_outputs.append(outputs)\n",
    "            all_targets.append(targets)\n",
    "            losses.append(loss if isinstance(loss, float) else loss.item())\n",
    "\n",
    "    all_outputs = np.concatenate(all_outputs)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "\n",
    "    auc = calculate_auc(all_targets, all_outputs)\n",
    "    avg_loss = np.mean(losses)\n",
    "\n",
    "    return avg_loss, auc\n",
    "\n",
    "\n",
    "def calculate_auc(targets, outputs):\n",
    "    \"\"\"\n",
    "    Compute AUC (Area Under Curve) score for each class and return the average.\n",
    "    Only includes classes that have at least one positive example.\n",
    "    \"\"\"\n",
    "    num_classes = targets.shape[1]\n",
    "    aucs = []\n",
    "\n",
    "    # Convert logits to probabilities\n",
    "    probs = 1 / (1 + np.exp(-outputs))\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        if np.sum(targets[:, i]) > 0:  # Skip if the class has no positives\n",
    "            class_auc = roc_auc_score(targets[:, i], probs[:, i])\n",
    "            aucs.append(class_auc)\n",
    "\n",
    "    return np.mean(aucs) if aucs else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4413470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(df, cfg):\n",
    "    \"\"\"Train the model using spectrogram images (either precomputed or created during training).\"\"\"\n",
    "\n",
    "    # Load list of bird species from taxonomy file\n",
    "    taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
    "    species_ids = taxonomy_df['primary_label'].tolist()\n",
    "    cfg.num_classes = len(species_ids)\n",
    "\n",
    "    # Apply debug settings if needed\n",
    "    if cfg.debug:\n",
    "        cfg.update_debug_settings()\n",
    "\n",
    "    # Try to load precomputed spectrograms\n",
    "    spectrograms = None\n",
    "    if cfg.LOAD_DATA:\n",
    "        print(\"Trying to load saved mel spectrograms...\")\n",
    "        try:\n",
    "            spectrograms = np.load(cfg.spectrogram_npy, allow_pickle=True).item()\n",
    "            print(f\"Loaded {len(spectrograms)} spectrograms.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load spectrograms: {e}\")\n",
    "            print(\"Will generate spectrograms during training instead.\")\n",
    "            cfg.LOAD_DATA = False\n",
    "\n",
    "    # If not loading, prepare to generate during training\n",
    "    if not cfg.LOAD_DATA:\n",
    "        print(\"Spectrograms will be created during training.\")\n",
    "        \n",
    "        # Check for required columns\n",
    "        if 'filename' not in df.columns:\n",
    "            if 'filepath' in df.columns:\n",
    "                df['filename'] = df['filepath'].apply(lambda x: os.path.relpath(x, cfg.train_datadir))\n",
    "            else:\n",
    "                raise ValueError(\"Metadata must contain either 'filename' or 'filepath' column.\")\n",
    "\n",
    "        # Create file path and sample name\n",
    "        df['filepath'] = df['filename'].apply(lambda x: os.path.join(cfg.train_datadir, x))\n",
    "        if 'samplename' not in df.columns:\n",
    "            df['samplename'] = df['filename'].apply(\n",
    "                lambda x: f\"{x.split('/')[0]}-{os.path.splitext(os.path.basename(x))[0]}\"\n",
    "            )\n",
    "\n",
    "    # Set up cross-validation\n",
    "    skf = StratifiedKFold(n_splits=cfg.n_fold, shuffle=True, random_state=cfg.seed)\n",
    "    best_scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['primary_label'])):\n",
    "        if fold not in cfg.selected_folds:\n",
    "            continue\n",
    "\n",
    "        print(f'\\n{\"=\"*30} Fold {fold} {\"=\"*30}')\n",
    "\n",
    "        # Split data\n",
    "        train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "        val_df = df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "        print(f'Training samples: {len(train_df)}')\n",
    "        print(f'Validation samples: {len(val_df)}')\n",
    "\n",
    "        # Create datasets and data loaders\n",
    "        train_dataset = BirdCLEFDatasetFromPNG(train_df, cfg, mode='train')\n",
    "        val_dataset = BirdCLEFDatasetFromPNG(val_df, cfg, mode='valid')\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, batch_size=cfg.batch_size, shuffle=True,\n",
    "            num_workers=cfg.num_workers, pin_memory=True,\n",
    "            collate_fn=collate_fn, drop_last=True\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, batch_size=cfg.batch_size, shuffle=False,\n",
    "            num_workers=cfg.num_workers, pin_memory=True,\n",
    "            collate_fn=collate_fn\n",
    "        )\n",
    "\n",
    "        # Build model and training components\n",
    "        model = BirdCLEFModel(cfg).to(cfg.device)\n",
    "        optimizer = get_optimizer(model, cfg)\n",
    "        criterion = get_criterion(cfg)\n",
    "\n",
    "        # Set up learning rate scheduler\n",
    "        if cfg.scheduler == 'OneCycleLR':\n",
    "            scheduler = lr_scheduler.OneCycleLR(\n",
    "                optimizer,\n",
    "                max_lr=cfg.lr,\n",
    "                steps_per_epoch=len(train_loader),\n",
    "                epochs=cfg.epochs,\n",
    "                pct_start=0.1\n",
    "            )\n",
    "        else:\n",
    "            scheduler = get_scheduler(optimizer, cfg)\n",
    "\n",
    "        # Start training loop\n",
    "        best_auc = 0\n",
    "        best_epoch = 0\n",
    "\n",
    "        for epoch in range(cfg.epochs):\n",
    "            print(f\"\\nEpoch {epoch+1} of {cfg.epochs}\")\n",
    "\n",
    "            # Train for one epoch\n",
    "            train_loss, train_auc = train_one_epoch(\n",
    "                model, train_loader, optimizer, criterion, cfg.device,\n",
    "                scheduler if isinstance(scheduler, lr_scheduler.OneCycleLR) else None\n",
    "            )\n",
    "\n",
    "            # Validate model\n",
    "            val_loss, val_auc = validate(model, val_loader, criterion, cfg.device)\n",
    "\n",
    "            # Step the scheduler\n",
    "            if scheduler and not isinstance(scheduler, lr_scheduler.OneCycleLR):\n",
    "                if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):\n",
    "                    scheduler.step(val_loss)\n",
    "                else:\n",
    "                    scheduler.step()\n",
    "\n",
    "            print(f\"Train Loss: {train_loss:.4f}, AUC: {train_auc:.4f}\")\n",
    "            print(f\"Val Loss: {val_loss:.4f}, AUC: {val_auc:.4f}\")\n",
    "\n",
    "            # Save model if it's the best so far\n",
    "            if val_auc > best_auc:\n",
    "                best_auc = val_auc\n",
    "                best_epoch = epoch + 1\n",
    "                print(f\"New best AUC: {best_auc:.4f} at epoch {best_epoch}\")\n",
    "                torch.save(model.state_dict(), f\"model_fold{fold}.pth\")\n",
    "\n",
    "        # Store best score\n",
    "        best_scores.append(best_auc)\n",
    "        print(f\"\\nBest AUC for fold {fold}: {best_auc:.4f} at epoch {best_epoch}\")\n",
    "\n",
    "        # Clear memory\n",
    "        del model, optimizer, scheduler, train_loader, val_loader\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    # Print overall results\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Cross-Validation Results:\")\n",
    "    for i, score in enumerate(best_scores):\n",
    "        print(f\"Fold {cfg.selected_folds[i]}: AUC = {score:.4f}\")\n",
    "    print(f\"Average AUC: {np.mean(best_scores):.4f}\")\n",
    "    print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5cd5847e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading training data...\n",
      "\n",
      "Starting training...\n",
      "LOAD_DATA is set to False\n",
      "Will generate spectrograms on-the-fly during training\n",
      "Will generate spectrograms on-the-fly during training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\envs\\torch-cuda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== Fold 0 ==============================\n",
      "Training set: 130628 samples\n",
      "Validation set: 32657 samples\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "055f0c07beb948109232abc97c2c2d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5cdaeaf1594cc3b09aa295cd5f1219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0333, Train AUC: 0.6608\n",
      "Val Loss: 0.0267, Val AUC: 0.8239\n",
      "New best AUC: 0.8239 at epoch 1\n",
      "\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "426af687f39f41ddb73dcf7cee683caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a240bb3620d142f49840eb8d1b300687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0254, Train AUC: 0.8329\n",
      "Val Loss: 0.0229, Val AUC: 0.8910\n",
      "New best AUC: 0.8910 at epoch 2\n",
      "\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5af71e3771cb436b8023735da4ffdb02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb34dca26ff04b0ebf5b49119f0958c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0221, Train AUC: 0.9001\n",
      "Val Loss: 0.0203, Val AUC: 0.9233\n",
      "New best AUC: 0.9233 at epoch 3\n",
      "\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6840f3c5aba44f8b990df94bc39a964e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292d74d06a7845c0a804007f0b28a4c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0198, Train AUC: 0.9303\n",
      "Val Loss: 0.0185, Val AUC: 0.9368\n",
      "New best AUC: 0.9368 at epoch 4\n",
      "\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714b167a602b4765aebaf7cb40a33973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e02d203bbdd41bf8285eeae7348ed21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0181, Train AUC: 0.9493\n",
      "Val Loss: 0.0176, Val AUC: 0.9433\n",
      "New best AUC: 0.9433 at epoch 5\n",
      "\n",
      "Best AUC for fold 0: 0.9433 at epoch 5\n",
      "\n",
      "============================== Fold 1 ==============================\n",
      "Training set: 130628 samples\n",
      "Validation set: 32657 samples\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6f3ce182cc420f8c1f7890c35a8660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970d5a8126db412fb5279ed37b0c27f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0330, Train AUC: 0.6727\n",
      "Val Loss: 0.0264, Val AUC: 0.8337\n",
      "New best AUC: 0.8337 at epoch 1\n",
      "\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10396ec9114482496f7403d344391f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864a9933352446b8bf903ffb2613b8f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0252, Train AUC: 0.8369\n",
      "Val Loss: 0.0230, Val AUC: 0.8983\n",
      "New best AUC: 0.8983 at epoch 2\n",
      "\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa09e674ad6484ea6249f9c156a5a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dadaf6f4f035442d9e161e60aee3dbfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0221, Train AUC: 0.9007\n",
      "Val Loss: 0.0203, Val AUC: 0.9243\n",
      "New best AUC: 0.9243 at epoch 3\n",
      "\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "760ecb2ab9a44913a038e3a5557c48cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7879466ca5b74458b7308b0f52a85113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0197, Train AUC: 0.9331\n",
      "Val Loss: 0.0186, Val AUC: 0.9384\n",
      "New best AUC: 0.9384 at epoch 4\n",
      "\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486eeb93c63c493f844466d0b74e447d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd7ced8d1f5476db105d9bac698cc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0181, Train AUC: 0.9474\n",
      "Val Loss: 0.0176, Val AUC: 0.9470\n",
      "New best AUC: 0.9470 at epoch 5\n",
      "\n",
      "Best AUC for fold 1: 0.9470 at epoch 5\n",
      "\n",
      "============================== Fold 2 ==============================\n",
      "Training set: 130628 samples\n",
      "Validation set: 32657 samples\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc7d3d96e3974823bb1e60d19124643b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e36375984d4085a893a2f673245cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0330, Train AUC: 0.6712\n",
      "Val Loss: 0.0264, Val AUC: 0.8246\n",
      "New best AUC: 0.8246 at epoch 1\n",
      "\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10bb0c9ea815499c81fdf8942ffd029a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6895bc5f2baf402dafac193a82700671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0251, Train AUC: 0.8414\n",
      "Val Loss: 0.0227, Val AUC: 0.8974\n",
      "New best AUC: 0.8974 at epoch 2\n",
      "\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11407fd65cd445c1aca45c2dd6850b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64fe81a5efd04bdcbb4a0e549922fe0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0219, Train AUC: 0.9005\n",
      "Val Loss: 0.0201, Val AUC: 0.9285\n",
      "New best AUC: 0.9285 at epoch 3\n",
      "\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66064edef1b4192a8f04581350d8f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b456b5dade8479ba3af3e2cf73fb462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0196, Train AUC: 0.9331\n",
      "Val Loss: 0.0184, Val AUC: 0.9419\n",
      "New best AUC: 0.9419 at epoch 4\n",
      "\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62119ca5baa541e0b207045d832707b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ac56a0fbaa47ab9532366a3acdcc06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0180, Train AUC: 0.9490\n",
      "Val Loss: 0.0175, Val AUC: 0.9473\n",
      "New best AUC: 0.9473 at epoch 5\n",
      "\n",
      "Best AUC for fold 2: 0.9473 at epoch 5\n",
      "\n",
      "============================== Fold 3 ==============================\n",
      "Training set: 130628 samples\n",
      "Validation set: 32657 samples\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c22d9b1fa4d4943a0ac0ea8a6ca7112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d517339387ec47d4845a850d993aabe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0332, Train AUC: 0.6640\n",
      "Val Loss: 0.0265, Val AUC: 0.8099\n",
      "New best AUC: 0.8099 at epoch 1\n",
      "\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbbec16c51034073bdb3afa48720e691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d49ce26ceac04c49b303f0ff656c6532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0254, Train AUC: 0.8297\n",
      "Val Loss: 0.0228, Val AUC: 0.8974\n",
      "New best AUC: 0.8974 at epoch 2\n",
      "\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a61cb0317e7f41e9affcc69af49f3d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1ba5ad30fb4752ac953496d6637e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0223, Train AUC: 0.8928\n",
      "Val Loss: 0.0203, Val AUC: 0.9289\n",
      "New best AUC: 0.9289 at epoch 3\n",
      "\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f65546d66e84a85a0f02397b0db3646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50815a60390c4ded82c280e2df56ac61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0198, Train AUC: 0.9311\n",
      "Val Loss: 0.0186, Val AUC: 0.9437\n",
      "New best AUC: 0.9437 at epoch 4\n",
      "\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fbef009f2d44936ae1d99cead248cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a25c0b4b9acf44babe31c5e7e13dd962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0182, Train AUC: 0.9483\n",
      "Val Loss: 0.0177, Val AUC: 0.9493\n",
      "New best AUC: 0.9493 at epoch 5\n",
      "\n",
      "Best AUC for fold 3: 0.9493 at epoch 5\n",
      "\n",
      "============================== Fold 4 ==============================\n",
      "Training set: 130628 samples\n",
      "Validation set: 32657 samples\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda8a9f3488d469793a6bb702d470d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "039a3d986f0b461c9230f6d612595c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0333, Train AUC: 0.6625\n",
      "Val Loss: 0.0267, Val AUC: 0.8176\n",
      "New best AUC: 0.8176 at epoch 1\n",
      "\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31b975bb94842cd9e60ffe3426bf0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f446a9d88db42cabc20171b8352d4e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0254, Train AUC: 0.8316\n",
      "Val Loss: 0.0231, Val AUC: 0.8966\n",
      "New best AUC: 0.8966 at epoch 2\n",
      "\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6dbd1d0f4014b34a9bbc12c4c1cbced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415dca9d3da24857a7b74d39308fade7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0224, Train AUC: 0.8934\n",
      "Val Loss: 0.0207, Val AUC: 0.9271\n",
      "New best AUC: 0.9271 at epoch 3\n",
      "\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b9936518c94cd69ba718ac4cf62370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7cf91377a464c7d840f4a160c004909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0199, Train AUC: 0.9314\n",
      "Val Loss: 0.0186, Val AUC: 0.9446\n",
      "New best AUC: 0.9446 at epoch 4\n",
      "\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c7b19629c1e4a12b9d21320e79d6bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41646e7bfebe4eb7877bfb9b37b775e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0184, Train AUC: 0.9473\n",
      "Val Loss: 0.0178, Val AUC: 0.9494\n",
      "New best AUC: 0.9494 at epoch 5\n",
      "\n",
      "Best AUC for fold 4: 0.9494 at epoch 5\n",
      "\n",
      "============================================================\n",
      "Cross-Validation Results:\n",
      "Fold 0: 0.9433\n",
      "Fold 1: 0.9470\n",
      "Fold 2: 0.9473\n",
      "Fold 3: 0.9493\n",
      "Fold 4: 0.9494\n",
      "Mean AUC: 0.9473\n",
      "============================================================\n",
      "\n",
      "✅ Saved best model to: best_model.pth (copied from model_fold0.pth)\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import time\n",
    "    import shutil\n",
    "\n",
    "    print(\"\\nLoading training data...\")\n",
    "    train_df = pd.read_csv(cfg.train_csv)\n",
    "    taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
    "\n",
    "    print(\"\\nStarting training...\")\n",
    "    print(f\"LOAD_DATA is set to {cfg.LOAD_DATA}\")\n",
    "    if cfg.LOAD_DATA:\n",
    "        print(\"Using pre-computed mel spectrograms from NPY file\")\n",
    "    else:\n",
    "        print(\"Will generate spectrograms on-the-fly during training\")\n",
    "\n",
    "    run_training(train_df, cfg)\n",
    "\n",
    "    # Optional: save the best fold model as \"best_model.pth\"\n",
    "    best_fold = cfg.selected_folds[0]  # You could change logic here\n",
    "    best_model_path = f\"model_fold{best_fold}.pth\"\n",
    "    if os.path.exists(best_model_path):\n",
    "        shutil.copy(best_model_path, \"best_model.pth\")\n",
    "        print(f\"\\n✅ Saved best model to: best_model.pth (copied from model_fold{best_fold}.pth)\")\n",
    "\n",
    "    print(\"\\nTraining complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3680dc17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
